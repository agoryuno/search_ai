{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from callformer.transformer import ModelDimensions, CallFormer\n",
    "from callformer.tokenizer import Tokenizer\n",
    "\n",
    "import pickle\n",
    "from copy import copy\n",
    "from datetime import date\n",
    "\n",
    "DATA_PATH = \"full_samples.pkl\"\n",
    "MODEL_PATH = \"drive/MyDrive/search_ai/callformer_model.chkpt\"\n",
    "\n",
    "\n",
    "with open(DATA_PATH, \"rb\") as f:\n",
    "    full_samples = pickle.load(f)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "token_samples = []\n",
    "\n",
    "tokens = [{\"call\": \"<|searchnotes|>\",\n",
    "           \"args\": []},\n",
    "           {\"call\": \"<|summarize|>\"}]\n",
    "\n",
    "for sample in full_samples:\n",
    "    search_start_date = \"\"\n",
    "    if sample[2][0] != -1:\n",
    "        search_start_date = f'\"{date(year=sample[2][0], month=sample[2][1], day=sample[2][2]).strftime(\"%Y-%m-%d\")}\"'\n",
    "    call_string = (\n",
    "        f'{tokens[0][\"call\"]}'\n",
    "        f'({search_start_date})'\n",
    "        f'{tokens[1][\"call\"]}'\n",
    "        )\n",
    "    toks = tokenizer.encode(call_string)\n",
    "    token_samples.append((\n",
    "                         sample[0], \n",
    "                         sample[1],\n",
    "                         sample[2], \n",
    "                         torch.from_numpy(np.array(sample[3])).unsqueeze(0).float(),\n",
    "                         toks))\n",
    "    \n",
    "\n",
    "\n",
    "class CallFormerDataset(Dataset):\n",
    "    def __init__(self, samples, model_dims: ModelDimensions):\n",
    "        self.samples = samples\n",
    "        self.n_ctx = model_dims.n_ctx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.samples[idx][-1]\n",
    "        full_seq = torch.hstack( (\n",
    "                        torch.Tensor([tokenizer.sot]), \n",
    "                        seq,\n",
    "                        torch.Tensor([tokenizer.eot]),))\n",
    "        input = F.pad(full_seq[:-2], (0, self.n_ctx - full_seq.shape[-1]+2), value=tokenizer.pad)\n",
    "        target = F.pad(full_seq[2:], (0, self.n_ctx - full_seq.shape[-1]+2), value=tokenizer.pad)\n",
    "        \n",
    "        embedding = self.samples[idx][-2]\n",
    "\n",
    "        assert embedding.ndim in (2, 3)\n",
    "        if embedding.ndim == 2:\n",
    "            embedding = embedding.unsqueeze(0)\n",
    "\n",
    "        return embedding, input.to(torch.long), target.to(torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = token_samples[0][-2].shape[-1]\n",
    "\n",
    "model_dims = ModelDimensions(\n",
    "                n_vocab=tokenizer.vocab_size,\n",
    "                n_ctx=100,\n",
    "                n_state=STATE_SIZE,\n",
    "                n_head=8,\n",
    "                n_layer=2)\n",
    "\n",
    "model = CallFormer(model_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3250 [00:00<?, ?it/s]/home/goryunov/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  0%|          | 5/3250 [00:16<3:16:08,  3.63s/it]"
     ]
    }
   ],
   "source": [
    "ds = CallFormerDataset(token_samples, model_dims)\n",
    "dloader = DataLoader(ds, batch_size=2, shuffle=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "for n in range(epochs):\n",
    "    for embedding, input, target in tqdm(dloader):\n",
    "        logits = model.decoder(input, embedding)\n",
    "        result = logits[:, 1:, :]\n",
    "        \n",
    "        # check that `result` doesn't contain and nan values\n",
    "        if torch.isnan(result).any():\n",
    "            print (result)\n",
    "            assert False\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(result.mT, target[...,:-1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss.item() < min_loss:\n",
    "            min_loss = loss.item()\n",
    "            print(min_loss)\n",
    "            #save_model(model, optimizer, \"callformer.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
